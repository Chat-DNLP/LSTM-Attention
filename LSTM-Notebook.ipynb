{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 2: Implementación de un mecanismo de atención en un modelo Seq2Seq con LSTMs\n",
    "\n",
    "Partiendo del código del modelo seq2seq con feedback para tareas de Traducción Automática Neuronal (NMT) del notebook anterior, se debe implementar el modelo de atención de Bahdanau o Luong.\n",
    "\n",
    "Objetivos de la práctica:\n",
    "- Entender el funcionamiento de los modelos Seq2Seq con LSTMs.\n",
    "- Comprender e implementar mecanismos de atención."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pln",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
